{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fastai2019L8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "MIZa3angVaPq",
        "BQH_7yaWXP-r",
        "SJN7LlGSZxZX",
        "dqT_gAfHdc7S"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paruliansaragi/Lessons-from-fast.ai/blob/master/Fastai2019L8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJTiu6iCj3WW",
        "colab_type": "text"
      },
      "source": [
        "# Matmul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EopMZkf-d38n",
        "colab_type": "text"
      },
      "source": [
        "### imports data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWe7ALorTEen",
        "colab_type": "code",
        "outputId": "37a7b5c7-d37b-4e92-892d-da34ee048e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "!pip install fastai"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.55)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (19.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.3.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.16.4)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.1.21)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.24.2)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.6)\n",
            "Requirement already satisfied: typing; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (3.7.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.6.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.21.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (7.0.8)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.6.16)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (41.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.0.18->fastai) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjDIh-HNTMQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYhde92nTc5q",
        "colab_type": "code",
        "outputId": "eb86f1d3-f2b8-4798-f4c7-cfc31adf5e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = datasets.download_data(MNIST_URL, ext='.gz'); path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/mnist.pkl.gz')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQpW11bOTngm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with gzip.open(path, 'rb') as f:\n",
        "  ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmq4BheNTz4t",
        "colab_type": "code",
        "outputId": "8112dcd1-cc70-4e65-b149-8bc7394c3d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))# map takes function and does that to all elements of array\n",
        "# in this case apply torch tensor to each \n",
        "n,c = x_train.shape\n",
        "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " torch.Size([50000, 784]),\n",
              " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
              " torch.Size([50000]),\n",
              " tensor(0),\n",
              " tensor(9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Sj6BlMUDdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert n==y_train.shape[0]==50000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WO_JKR9UW7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icgmLIKyUiv1",
        "colab_type": "code",
        "outputId": "e30836b6-4ad7-4a50-b566-97c3cde916f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img = x_train[0]\n",
        "img.view(28,28).type()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1wLxmTjUx_b",
        "colab_type": "code",
        "outputId": "87784b8d-a768-4374-eba3-a9e7d99050d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E81g7VUkUm1_",
        "colab_type": "code",
        "outputId": "21581324-82e4-4855-9f4a-15f8929a70ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(img.view((28,28))) # .view reshapes \n",
        "#in this case reshape 784 long vector into 28x28"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fba41591668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TKMX3laVTOH",
        "colab_type": "text"
      },
      "source": [
        "### Initial Python Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVBZMXWSUpoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = torch.randn(784, 10)#random init\n",
        "bias = torch.zeros(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIZa3angVaPq",
        "colab_type": "text"
      },
      "source": [
        "### Mat mul loops Python\n",
        "\n",
        "- example of mat mul from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECKd_AevVY-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(a,b):\n",
        "  rows, cols = a.shape\n",
        "  brows, bcols = b.shape\n",
        "  assert cols==brows\n",
        "  c = torch.zeros(rows, bcols)\n",
        "  for i in range(rows): #for each rows\n",
        "    for j in range(bcols): #for each bcol in each row\n",
        "      for k in range(cols): #for each element in col in each bcol in each row do multiplication and summation\n",
        "        c[i,j] += a[i,k] * b[k,j]\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTAaqpFhWUIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m1 = x_valid[:5]\n",
        "m2 = weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJrz5Y9DWoHL",
        "colab_type": "code",
        "outputId": "d7224020-bfed-4057-e09b-10efabb5b4ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m1.shape, m2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4HMFSCRWpVp",
        "colab_type": "code",
        "outputId": "25b5b0d8-642b-4bad-8f2c-f2ad51b2388b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time t1=matmul(m1, m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 718 ms, sys: 0 ns, total: 718 ms\n",
            "Wall time: 720 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RO-6QbHXG5h",
        "colab_type": "code",
        "outputId": "4b3e9e73-e02a-4a71-a969-d131c6fbeb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iig9D63MXMCK",
        "colab_type": "code",
        "outputId": "ce76f276-9a77-4693-dffc-0d2421690cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "t1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1.3030, -16.7730,   7.1580,  -5.9198,   7.0124,   8.4855,  -0.2477,\n",
              "           7.2836,  -2.9298, -17.9405],\n",
              "        [  1.6914,  -5.8262,  19.0501,   2.6722,   0.7795,  -3.2849,  -9.0679,\n",
              "          12.0541,  -2.5347, -29.4379],\n",
              "        [  1.4314,  -6.3727,  -1.2675,  12.6470,  10.1448,   0.6885,  -6.4634,\n",
              "           6.6194,   5.3929,   6.1812],\n",
              "        [  1.5566,  -7.8667, -19.5515, -16.5700,   6.7333,   0.2652,  -9.8393,\n",
              "           7.5904,   0.5260, -13.2597],\n",
              "        [  7.3145, -14.9225, -11.1600,   9.2615,   8.9004,  -1.5887,  -4.1688,\n",
              "           5.5148,   2.2683,  -5.4907]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQH_7yaWXP-r",
        "colab_type": "text"
      },
      "source": [
        "### Elementwise Ops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP9QSsSWXNL7",
        "colab_type": "code",
        "outputId": "05a67a67-dc59-4274-dea7-32e75273b27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tensor([10., 6, -4])\n",
        "b = tensor([2., 8, 7])\n",
        "a,b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54bBDMQoXo0J",
        "colab_type": "code",
        "outputId": "d5922a2e-f8c7-431e-b865-7b2f52672fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a+b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12., 14.,  3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVZkjFo1XpK5",
        "colab_type": "code",
        "outputId": "e7476e42-95a4-449a-ffff-fb19066649df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(a<b).float().mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6667)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHebJZOKXulF",
        "colab_type": "text"
      },
      "source": [
        "Frobenius Norm:\n",
        "\n",
        "$||A||_F = (\\sum^{n}_{i,j=1}|a_{ij}|^2)^{1/2}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xv-hI4oXsn7",
        "colab_type": "code",
        "outputId": "060f6464-b834-4476-952a-50c133e882f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]);m\n",
        "(m*m).sum().sqrt() # equivalent to the above frobenius norm equation\n",
        "# sum over two for loops called i from 1 to n, and loop over j from 1 to n, \n",
        "#then grab something out of matrix 'a' at position i,j squared then sum all those\n",
        "#and take the square root"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.8819)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYAT8oLjY9C_",
        "colab_type": "text"
      },
      "source": [
        "#### Elementwise matmul"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKn1p756YDtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#that means we can replace the loop in the above mat mul\n",
        "def matmul(a,b):\n",
        "  rows, cols = a.shape\n",
        "  brows, bcols = b.shape\n",
        "  assert cols==brows\n",
        "  c = torch.zeros(rows, bcols)\n",
        "  for i in range(rows): # a[i, :] =  for each row [1,2,3]\n",
        "    for j in range(bcols): # b[:, j] = for each col [1,\n",
        "                                          #2,\n",
        "                                          #3]\n",
        "      c[i,j] = (a[i,:] * b[:,j]).sum()#\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkZXgMy4ZPQB",
        "colab_type": "code",
        "outputId": "0cb5ad06-30c7-4ce6-c016-5999dfea3e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 1.18 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJN7LlGSZxZX",
        "colab_type": "text"
      },
      "source": [
        "### Broadcasting\n",
        "\n",
        "- broadcast something across all elements. It describes how arrays with different shapes are treated during arithmetic operations.\n",
        "- describes how numpy treats arrays with different shapes during arithmetic operations. The smaller array is broadcast across the larger so they have compatible shapes. Means of vectorizing array operations so looping occurs in C not python. Doing so without needless copies of data.\n",
        "- gets rid of loops at C or cuda speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUm3jCOyZTJG",
        "colab_type": "code",
        "outputId": "ea1fde9c-8766-4ffb-f052-ca4e541e4b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#bc with scalar\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10.,  6., -4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whqQQozAaYZh",
        "colab_type": "code",
        "outputId": "966d22d1-80f2-4299-b986-bdd41a9d583a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a > 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQCmKdF1abJk",
        "colab_type": "text"
      },
      "source": [
        "How does this work? The value of 0 is broadcast three times then does elemtwise operation. You broadcast a scalar to a tensor here.\n",
        "\n",
        "#### Broadcasting a vector to a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6-7nNxDaZYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = tensor([1.,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j3_S1oYapJh",
        "colab_type": "code",
        "outputId": "70c8c433-4220-405d-8b7b-1f688481c605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m + c #it broadcast the row across all of m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  4.,  6.],\n",
              "        [ 5.,  7.,  9.],\n",
              "        [ 8., 10., 12.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ldmQa35aqJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = c.expand_as(m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwrNqcdSbB2-",
        "colab_type": "code",
        "outputId": "4106beda-7e9f-4889-9319-bc31256c4578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [1., 2., 3.],\n",
              "        [1., 2., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs2Zyp3zbCJ-",
        "colab_type": "code",
        "outputId": "289af560-e6e6-4875-c658-1d315b1bc7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m + t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  4.,  6.],\n",
              "        [ 5.,  7.,  9.],\n",
              "        [ 8., 10., 12.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECHcX1WKbGWw",
        "colab_type": "code",
        "outputId": "beb89a53-20e9-4a46-fe7c-600b40b92474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.stride()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHNOk6EbbJ4C",
        "colab_type": "code",
        "outputId": "6a722735-48be-45b9-e762-b4e61fac80c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.unsqueeze(0), c.unsqueeze(0).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3.]]), torch.Size([1, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSB8u236cJmy",
        "colab_type": "code",
        "outputId": "3af1c216-0e05-4077-8f29-b02ebe6b5810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c.unsqueeze(1), c.unsqueeze(1).shape # looks like a column"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.]]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB-yV1XYcL77",
        "colab_type": "code",
        "outputId": "1295b24c-60db-4a2c-99f9-77b60e5d6557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None, :], c[None, :].shape # squeeze a new axis here please"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3.]]), torch.Size([1, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuFiHeD-ccK7",
        "colab_type": "code",
        "outputId": "1b95fd60-d4e3-4f43-f1e5-07249acf11f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c[:, None], c[:, None].shape # squeeze a new axis here please\n",
        "#same as unsqueeze( axis )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.]]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08z0h_-wcpFq",
        "colab_type": "code",
        "outputId": "8d487517-41b5-4a93-f791-4228c1bd67f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None].shape, c[..., None].shape # \"...\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mPjqh2Lc1EA",
        "colab_type": "code",
        "outputId": "720baa2f-3824-4b18-98d3-194963dae830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c[:, None].expand_as(m)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [2., 2., 2.],\n",
              "        [3., 3., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEDF2u6Bc-wF",
        "colab_type": "code",
        "outputId": "4418321f-3c57-43fc-9747-eda97c34d573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m + c[:, None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  3.,  4.],\n",
              "        [ 6.,  7.,  8.],\n",
              "        [10., 11., 12.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqT_gAfHdc7S",
        "colab_type": "text"
      },
      "source": [
        "### Matmul with broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyV5BT1YdD-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#that means we can replace the loop in the above mat mul\n",
        "def matmul(a,b):\n",
        "  rows, cols = a.shape\n",
        "  brows, bcols = b.shape\n",
        "  assert cols==brows\n",
        "  c = torch.zeros(rows, bcols)\n",
        "  for i in range(rows):\n",
        "    c[i] = (a[i  ].unsqueeze(-1) * b).sum(dim=0)\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-poTquYdwNm",
        "colab_type": "code",
        "outputId": "9ebe792e-34dc-4ac3-8f32-0647d386d936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 262 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipUsQtsNgAx6",
        "colab_type": "text"
      },
      "source": [
        "### Einstein Summation\n",
        "\n",
        "Einstein summation (`einsum`) is a compact representation for combining products and sums in a general way. The subscript strings in comma-separated list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeat it is summed, so `np.einsum('i,i', a, b)` is equivalent to `np.inner(a,b)`. If a label appears only once, it is not summed, so `np.einsum('i'm a)` produces a view of a with no changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt22C4mHdzOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# einstein summation notation inside a string. left of arrow is input right is input delimeted by comma, rank of input given by however many letters\n",
        "def matmul(a,b): return torch.einsum('ik,kj->ij', a, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSai9RR1gS_w",
        "colab_type": "code",
        "outputId": "96456051-af64-4572-9fba-3554b06491e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 101.10 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 33.1 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gFQ6zn_hZUJ",
        "colab_type": "text"
      },
      "source": [
        "### pytorch op matmul"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7f9kfvNgzvw",
        "colab_type": "code",
        "outputId": "a9839b5b-8f02-4dd4-853d-c5cbc57b7d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%timeit -n 10 t2= m1.matmul(m2)\n",
        "#50,000X faster than python\n",
        "#matmul doesn't fit in cache and you forget the contents of what we originally operated and we go to ram to get it again\n",
        "#matmul makes mini matrices of the matrix.\n",
        "# Pytorch doesn't even do this itself it uses blas = Basic Linear Algebra Sub-programme\n",
        "# where Intel, AMD, NVidia write this for you e.g. Cublas or BKL\n",
        "# program is limited by what your blas can handle and you dont write it in python.\n",
        "# tensor comprehensions : in pytorch, ways to compile these things."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 97.42 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 5.78 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXHX4FHXhjQI",
        "colab_type": "code",
        "outputId": "5601b43a-00e0-475b-f9de-f6343339f564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%timeit -n 10 t2= m1@m2 # not just matmul but same speed since it calls same thing"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 18.93 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 5.92 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx2Ee0hKj5g9",
        "colab_type": "text"
      },
      "source": [
        "# Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEnCEycDi8Dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "  path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "  with gzip.open(path, 'rb') as f:\n",
        "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "  return map(tensor, (x_train, y_train, x_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjnFMbd0kVxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lgo8qV6kanM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBqG6sM8kehu",
        "colab_type": "code",
        "outputId": "21e14615-f915-4592-8abd-99fe773613ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_mean,train_std = x_train.mean(), x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLn9fZyikgOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "# normalise both in same way\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-BHgdc6lHvb",
        "colab_type": "code",
        "outputId": "b54a4b3a-2574-4e3a-9ffe-6ae713882ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_mean,train_std = x_train.mean(), x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlSaWVwpGCc0",
        "colab_type": "code",
        "outputId": "b66aa8df-da5b-4f6d-e04e-48c28937cfda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "n,m,c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE3wn2UwGNWL",
        "colab_type": "text"
      },
      "source": [
        "## Foundations version\n",
        "### Basic Architecture\n",
        "\n",
        "- Model with 1 hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI4j3c6BGL5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#num hidden\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lBFD5M2GYv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simple kaiming init / he init\n",
        "# mean 0 std 1\n",
        "# if we dont the std and mean of our linear layer we get really bad mean and std\n",
        "w1 = torch.randn(m, nh)/math.sqrt(m)\n",
        "#w1 = torch.randn(m, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh, 1)/math.sqrt(nh)\n",
        "#w2 = torch.randn(nh, 1)\n",
        "b2 = torch.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXtMoXd6Gfvy",
        "colab_type": "code",
        "outputId": "05486425-2eed-48b3-bef2-51eab2e0e980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfbaZBNiGscZ",
        "colab_type": "code",
        "outputId": "a1b61aa9-8a4c-4ce8-e203-8ae79ae48ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_valid.mean(), x_valid.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0057), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4FKJd5kG2Lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_layer(x, w, b): return x@w + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hImuRUjJG_Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = linear_layer(x_valid, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQqD_SCSHCT0",
        "colab_type": "code",
        "outputId": "e5afb3a6-e2fd-43db-9406-21f1161dadd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.mean(), t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0316), tensor(0.9906))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBIz03ahHEVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXqQAR2iH7aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(linear_layer(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW4rdfmGIAiL",
        "colab_type": "code",
        "outputId": "4ac66b60-97c4-44bd-c136-a0ebb7478896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.mean(), t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3758), tensor(0.5824))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6_clfikIFEW",
        "colab_type": "text"
      },
      "source": [
        "- This doesn't give mean 0 and std 1. From pytorch docs: `a: the negative slope of the rectifier user after this layer (0 for ReLU by default)`\n",
        "\n",
        "$std = \\sqrt{ \\frac{2}{(1+a^2) * fanin} }$\n",
        "\n",
        "This was introducted in the paper that described the Imagenet-winning approach from *He et al: Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*. \n",
        "\n",
        "- Initialization of Filter Weights for Rectifiers : people used to initialize with random Gaussian distributions and led to poor training. Glorot and Bengio (Xavier initialization) : They describe one way to initialize is:\n",
        "\n",
        "$\\frac{\\sqrt{6}}{\\sqrt{numinputfilters + numoutputerfilters}}$\n",
        "\n",
        "We took everything smaller than 0 and removed it so it has half the std and not mean 0. \n",
        "\n",
        "All the paper does is does $2/m$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqg5LJ5GIDj8",
        "colab_type": "code",
        "outputId": "8194ff6f-125b-4e21-ac55-8c740804d1a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# kaiming init/ he init for relu\n",
        "w1 = torch.randn(m, nh)*math.sqrt(2/m)\n",
        "w1.mean(), w1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.6480e-05), tensor(0.0504))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUFJMLSVLvus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(linear_layer(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRisWb6nQhmN",
        "colab_type": "code",
        "outputId": "e8b06695-a7e0-4962-e97f-8f6e95de2fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.mean(), t.std()\n",
        "#it gives a bad mean since we deleted everything below 0 \n",
        "#jeremy has tried using x.clamp_min(0.) - 0.5 and it seems to help"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4307), tensor(0.7205))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYojmV-9QjUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n5u9RKyRCPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.zeros(m,nh)\n",
        "init.kaiming_normal_(w1, mode='fan_out')\n",
        "t = relu(linear_layer(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25XRg-e9SBo1",
        "colab_type": "code",
        "outputId": "0b282ab4-524e-4450-b07e-426f236a5951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.mean(), t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5255), tensor(0.8205))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u291u98SEUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "??init.kaiming_normal_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8dFFf6lSQHE",
        "colab_type": "code",
        "outputId": "b35c4da4-0667-4aeb-9b61-3373c50c2d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ctCeMHTDW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBLXhapkTFbm",
        "colab_type": "code",
        "outputId": "28af0e6e-8a18-4bc6-c501-a811c260e847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.nn.Linear(m, nh).weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIlV0xJlTHp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.functional.linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-znwlCpTK45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Conv2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xVEPycXTUCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.modules.conv._ConvNd.reset_parameters??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM9Cerg0TqKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIZtFar3TzF9",
        "colab_type": "code",
        "outputId": "2b9da477-368a-429a-87f4-9e826eea6262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# kaiming init/ he init for relu\n",
        "w1 = torch.randn(m, nh)*math.sqrt(2./m)\n",
        "t1 = relu(linear_layer(x_valid, w1, b1))\n",
        "t.mean(), t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5255), tensor(0.8205))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CtlxpSSUH0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(xb):\n",
        "  l1 = linear_layer(xb, w1, b1)\n",
        "  l2 = relu(l1)\n",
        "  l3 = linear_layer(l2, w2, b2)\n",
        "  return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz1N2D_XXS8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%timeit -n 10 _=model(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hig6rZ97XjoX",
        "colab_type": "text"
      },
      "source": [
        "### Loss function: MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R3DbQP6XVdv",
        "colab_type": "code",
        "outputId": "be717472-c6fc-4e7a-8425-8a49d418d519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model(x_valid).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHMqCvIsXsVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByRflIUCYmMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train, y_valid=y_train.float(),y_valid.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxcwUUuTYrYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTTa9PQ2Ytkj",
        "colab_type": "code",
        "outputId": "3d3415fa-1e06-4019-f608-433f9165bab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yql0N0ZfYuij",
        "colab_type": "code",
        "outputId": "c159d1f9-aea0-46da-fe07-2e58d608d1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mse(preds, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(26.5780)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-wXNo8ZQyY",
        "colab_type": "text"
      },
      "source": [
        "### That's a forward pass\n",
        "### Gradients and backward pass\n",
        "\n",
        "We do need to know matrix calculus and the chain rule. \n",
        "\n",
        "- we want the gradient w.r.t parameters.\n",
        "\n",
        "$dy/dx= dy/du * du/dx$\n",
        "\n",
        "You can just cross multiply and you can just get $dy/dx$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXu2-uaBZOPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_grad(inp, targ):\n",
        "  # gradient of loss w.r.t output of prev layer\n",
        "  # mse is just input - targ squared so the gradient is just 2 * input-target because the derivative of something^2 is just 2 * something\n",
        "  inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7nvHsjNbDZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_grad(inp, out):\n",
        "  #grad of relu w.r.t input activations\n",
        "  # it is just the input greater than 1 but because of the chain rule, so we need to multiply this with the gradient of the next layer\n",
        "  inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgwQpQ5Dbl63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "  # grad of matmul w.r.t input\n",
        "  # the gradient of a matrix product is simply, the matrix product with the transpose\n",
        "  inp.g = out.g @ w.t()\n",
        "  w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
        "  b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPpT-VwldLMa",
        "colab_type": "text"
      },
      "source": [
        "This function does both. It calls each gradient backwards in reverse order for chain rule. Each time we pass in the result of the forward pass, and it has access to the gradient of the next layer ~> this is backpropagation. It is the chain rule where we save the intermediate calculations and don't have to calculate them again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edzAPUhJcFkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "  #forward pass:\n",
        "  l1 = inp @ w1 + b1\n",
        "  l2 = relu(l1)\n",
        "  out = l2 @ w2 + b2\n",
        "  #we dont actually need loss in backward!\n",
        "  loss = mse(out, targ)\n",
        "  \n",
        "  #backward\n",
        "  mse_grad(out, targ)\n",
        "  lin_grad(l2, out, w2, b2)\n",
        "  relu_grad(l1, l2)\n",
        "  lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj20866Zc0Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_and_backward(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uYxx5kkc4xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1g = w1.g.clone()\n",
        "w2g = w2.g.clone()\n",
        "b1g = b1.g.clone()\n",
        "b2g = b2.g.clone()\n",
        "ig = x_train.g.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEC7v5yzdsoc",
        "colab_type": "text"
      },
      "source": [
        "Let's use autograd to check the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx0E3wkdsCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt2 = x_train.clone().requires_grad_(True)\n",
        "w12 = w1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b12 = b1.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)\n",
        "#turns tensor into and keeps track of (operations) forward pass to do gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSaU7nBkeWWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(inp, targ):\n",
        "  l1 = inp@w12 + b12\n",
        "  l2 = relu(l1)\n",
        "  out = l2@ w22 + b2\n",
        "  return mse(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UKo-kwQd7g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = forward(xt2, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUFt3ChreNbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn-523nmfTHT",
        "colab_type": "text"
      },
      "source": [
        "### Layers as Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIRzl5OQe8ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu():\n",
        "  def __call__(self, inp):\n",
        "    #dunder call means we can call this class as a function\n",
        "    self.inp = inp\n",
        "    self.out = inp.clamp_min(0.)-0.5\n",
        "    return self.out\n",
        "  \n",
        "  def backward(self): self.inp.g = (self.inp>0).float() * self.out.g\n",
        "    #same as before and we store self.inp.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6P_sb2ff01n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin():\n",
        "  def __init__(self, w, b): self.w, self.b = w,b\n",
        "  \n",
        "  def __call__(self,inp):\n",
        "    self.inp = inp\n",
        "    self.out = inp@self.w + self.b\n",
        "    return self.out\n",
        "  \n",
        "  def backward(self):\n",
        "    self.inp.g = self.out.g @ self.w.t()\n",
        "    #creating giant outer product, just to sum it, is inefficient!\n",
        "    self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "    self.b.g = self.out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmQ9IL_AguMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse():\n",
        "    def __call__(self, inp, targ):\n",
        "        self.inp = inp\n",
        "        self.targ = targ\n",
        "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erNPe56Ng6EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhNpuZhZg71K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic7Rccong9y0",
        "colab_type": "code",
        "outputId": "aa12d55a-3d93-41ae-a412-86618ad90f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 127 ms, sys: 0 ns, total: 127 ms\n",
            "Wall time: 127 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhP-cCo3g-28",
        "colab_type": "code",
        "outputId": "7a08efe9-974e-4edb-a0a5-f999c13923c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.25 s, sys: 4.13 s, total: 7.38 s\n",
            "Wall time: 7.39 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-GPsq0uhB_l",
        "colab_type": "text"
      },
      "source": [
        "### Module.forward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEl6VtzZhAtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module():\n",
        "    def __call__(self, *args):\n",
        "        self.args = args\n",
        "        self.out = self.forward(*args)\n",
        "        return self.out\n",
        "    \n",
        "    def forward(self): raise Exception('not implemented')\n",
        "    def backward(self): self.bwd(self.out, *self.args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb5qG7m8hGKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Module):\n",
        "    def forward(self, inp): return inp.clamp_min(0.)-0.5\n",
        "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awg0J8K-hH1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2VITiwphK0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse(Module):\n",
        "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
        "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG-kAEffhMib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt6Ot-yhhOcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuEzNZCShQTF",
        "colab_type": "code",
        "outputId": "c2dce8c8-0515-4b77-8078-461c2431fa28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 93.7 ms, sys: 5.89 ms, total: 99.6 ms\n",
            "Wall time: 103 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp4SzbUGhRhF",
        "colab_type": "code",
        "outputId": "287d210e-23f7-4127-9a47-6aadda454967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 220 ms, sys: 114 ms, total: 333 ms\n",
            "Wall time: 348 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBz0CM16hS7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = inp.t() @ out.g\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROOAplykhX4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0rkACOQhbAa",
        "colab_type": "code",
        "outputId": "2cb83b80-ed07-424b-8a3f-c80e3b8f60f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 123 ms, sys: 1.38 ms, total: 125 ms\n",
            "Wall time: 130 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0KnNI8chcqE",
        "colab_type": "code",
        "outputId": "686fe9e4-e814-43b5-f4f2-61eb0fecb6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 242 ms, sys: 5.45 ms, total: 248 ms\n",
            "Wall time: 251 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB57C18ghefs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gob9nuenhhBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        self.loss = mse\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x.squeeze(), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juv884Qchia-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mA3vHGkhkDo",
        "colab_type": "code",
        "outputId": "4d9b15e6-f9d1-402b-d8d7-13b70800567e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 89.5 ms, sys: 2.06 ms, total: 91.6 ms\n",
            "Wall time: 99.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LveI-2khlPH",
        "colab_type": "code",
        "outputId": "3da5b560-7d04-437a-8b27-695313fc1654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time loss.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 80.1 ms, sys: 792 µs, total: 80.9 ms\n",
            "Wall time: 85.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}